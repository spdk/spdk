{
  "comments": [
    {
      "key": {
        "uuid": "248e4f08_99c760d1",
        "filename": "include/spdk/blob.h",
        "patchSetId": 27
      },
      "lineNbr": 471,
      "author": {
        "id": 1012251
      },
      "writtenOn": "2018-05-02T07:20:47Z",
      "side": 1,
      "message": "Is this behavior generally acceptable? \n\nIf clone-\u003eback_bs_dev-\u003eback_bs_dev is thin provisioned, should the inflated clone be thin provisioned too?\n\nInheriting thin provisioning setting to the inflated clone is good enhancement? If yes, adding any TBD comment may be helpful.\n\nCurrently knowing if zeroes_bs_dev or not may not be possible because struct spdk_bs_dev doesn\u0027t have any usable information.",
      "range": {
        "startLine": 471,
        "startChar": 12,
        "endLine": 471,
        "endChar": 49
      },
      "revId": "45b26eec083cb13ce0b41e573aa90bab218a4b5b",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "6dc0df53_4b73aeb6",
        "filename": "include/spdk/blob.h",
        "patchSetId": 27
      },
      "lineNbr": 471,
      "author": {
        "id": 1013008
      },
      "writtenOn": "2018-05-04T15:34:54Z",
      "side": 1,
      "message": "If we want to create thin provisioned inflated blob we need to check if in any of ancestors page is allocated. I\u0027m thinking about something like this:\n\n/* Check if parent allocates page */\nstatic inline bool\n_spdk_bs_page_needs_allocation_next(struct spdk_blob *blob, uint32_t page)\n{\n\tstruct spdk_blob_bs_dev *b \u003d blob-\u003eback_bs_dev;\n\n\tif (_spdk_bs_page_is_allocated(blob, page)) {\n\t\t/* if page is allocated we need to claim it */\n\t\treturn true;\n\t}\n\n\tif (b \u003d\u003d NULL || b-\u003eblob \u003d\u003d NULL) {\n\t\t/* Blob have no back_bs_dev, so we do not need to allocate page */\n\t\treturn false;\n\t}\n\n\treturn _spdk_bs_page_needs_allocation_next(b-\u003eblob, page);\n}\n\n/* Check if page needs allocation */\nstatic inline bool\n_spdk_bs_page_needs_allocation(struct spdk_blob *blob, uint32_t page)\n{\n\tstruct spdk_blob_bs_dev *b \u003d blob-\u003eback_bs_dev;\n\n\tif (_spdk_bs_page_is_allocated(blob, page)) {\n\t\t/* Page is already allocated */\n\t\treturn false;\n\t}\n\n\t/* Blob have no back_bs_dev */\n\tif (b \u003d\u003d NULL || b-\u003eblob \u003d\u003d NULL) {\n\t\t/* Page is not allocated, but there\u0027s not bs_dev */\n\t\treturn false;\n\t}\n\n\t/* Check if any of ancessors have allocated page */\n\treturn _spdk_bs_page_needs_allocation_next(b-\u003eblob, page);\n}\n\nBut this is only an idea and requires more testing. For now, most of backing devices are read only (like snapshots), so we can assume that page allocation doesn\u0027t change on ancestor elsewhere problem with synchronization will be a little challenging.\n\nThis feature is required for Cinder integration (https://trello.com/c/zsQgOW5M/3-lvol-snpashots-clones). I can go ahead with this idea if there\u0027s no other objections.\n\nI had also alternative solution https://review.gerrithub.io/#/c/408332/ which doesn\u0027t require zero length writes and may let to inflate (touch) only a part of blob, so maybe mixing both is some alternative.",
      "parentUuid": "248e4f08_99c760d1",
      "range": {
        "startLine": 471,
        "startChar": 12,
        "endLine": 471,
        "endChar": 49
      },
      "revId": "45b26eec083cb13ce0b41e573aa90bab218a4b5b",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "744d57a3_04251f65",
        "filename": "lib/blob/blobstore.c",
        "patchSetId": 27
      },
      "lineNbr": 4176,
      "author": {
        "id": 1010531
      },
      "writtenOn": "2018-04-27T20:17:17Z",
      "side": 1,
      "message": "There are a number of race conditions that need to be handled (even assuming that this is only called from the metadata thread).\n\nThis loop confirms that there are enough clusters to inflate the blob right now, but the clusters are not claimed right up front. They\u0027re lazily claimed as the inflation happens (mostly because the inflation is a 0 length write to re-use code). That means that some time between when this check occurs and when the inflation for a cluster is actually triggered, there could be no free clusters remaining.",
      "revId": "45b26eec083cb13ce0b41e573aa90bab218a4b5b",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "72ed8a25_7c08f97d",
        "filename": "lib/blob/blobstore.c",
        "patchSetId": 27
      },
      "lineNbr": 4176,
      "author": {
        "id": 1013008
      },
      "writtenOn": "2018-04-30T16:02:48Z",
      "side": 1,
      "message": "Yes, this is more sanity test for inflate operation and it doesn\u0027t guarantee that operation success. The same situation is when we want to write the whole blob with a data. To solve this problem we may use freeze IO mechanism to made inflate more atomic (or at least freeze only these which requires cluster allocation). Other solution is to let application try to inflate, and if inflation fails let her to decide what to do with that. If this is not a common situation it can be more effective and clear.",
      "parentUuid": "744d57a3_04251f65",
      "revId": "45b26eec083cb13ce0b41e573aa90bab218a4b5b",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735",
      "unresolved": false
    }
  ]
}