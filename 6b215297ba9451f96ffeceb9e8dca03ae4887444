{
  "comments": [
    {
      "key": {
        "uuid": "0c2a3e14_4fe61fb7",
        "filename": "module/bdev/nvme/bdev_nvme.c",
        "patchSetId": 4
      },
      "lineNbr": 377,
      "author": {
        "id": 1012251
      },
      "writtenOn": "2019-11-12T07:46:31Z",
      "side": 1,
      "message": "Is it OK to return error here?\nDo we require application of bdev to implement retry code?\nI may be wrong but this looks against general principle.\nI think we may have to queue reset requests and process them sequentially.",
      "range": {
        "startLine": 377,
        "startChar": 53,
        "endLine": 377,
        "endChar": 79
      },
      "revId": "6b215297ba9451f96ffeceb9e8dca03ae4887444",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "c31ec3be_ce97bd40",
        "filename": "module/bdev/nvme/bdev_nvme.c",
        "patchSetId": 4
      },
      "lineNbr": 377,
      "author": {
        "id": 1011223
      },
      "writtenOn": "2019-11-12T17:34:37Z",
      "side": 1,
      "message": "Hi Shuhei,\n\nThanks for the review. I was actually not sure what to do in this case either. Later on in this callback chain we definitely do return an error code (see lines 298, 332, 341). However, I agree that the semantics of returning an error code here are slightly different. It\u0027s not that we attempted the operation and it failed, it\u0027s that we weren\u0027t able to attempt the reset because of the state of the bdev.\nThe reason I didn\u0027t queue resets is because I don\u0027t think users would want to  unconditionally do a reset twice in a row. My thought process is that once the first reset completes successfully, the bdev will be in a fixed state and we won\u0027t want to do the second reset. However, if the reset going on when this function is called fails, then we will find ourselves in a bad state again. In that case, we can try this function again.\nI am open to not returning a failure here, and just queueing the reset bdevio until the original reset completes, then returning the same return code for both bdevios. Do you think that would be a reasonable approach?",
      "parentUuid": "0c2a3e14_4fe61fb7",
      "range": {
        "startLine": 377,
        "startChar": 53,
        "endLine": 377,
        "endChar": 79
      },
      "revId": "6b215297ba9451f96ffeceb9e8dca03ae4887444",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "3503414d_8bf0c43c",
        "filename": "module/bdev/nvme/bdev_nvme.c",
        "patchSetId": 4
      },
      "lineNbr": 377,
      "author": {
        "id": 1011223
      },
      "writtenOn": "2019-11-12T20:51:44Z",
      "side": 1,
      "message": "Actually, I am not sure that queueing resets will work either because resets can come in on any thread on any bdev associated with the controller. So I would have to queue resets on a per I/O channel basis to avoid contention over a shared tailq, then I would have to do a for_each_channel on each bdev to free the queued resets before I clear the reset flag. While I am in the process of doing that, another reset could potentially come in on a thread. That spdk_bdev_io would be queued, and then never get completed. I think that trying to queue reset requests and batch complete them introduces too many possibilities for errors.\nSo I am back to thinking that failing the reset attempt when there is already one in progress is the right thing to do.",
      "parentUuid": "c31ec3be_ce97bd40",
      "range": {
        "startLine": 377,
        "startChar": 53,
        "endLine": 377,
        "endChar": 79
      },
      "revId": "6b215297ba9451f96ffeceb9e8dca03ae4887444",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "a60c8a3e_b9c0bd22",
        "filename": "module/bdev/nvme/bdev_nvme.c",
        "patchSetId": 4
      },
      "lineNbr": 377,
      "author": {
        "id": 1012251
      },
      "writtenOn": "2019-11-12T22:37:25Z",
      "side": 1,
      "message": "Thank you Seth for investigating my comments in detail.\n\nIs it possible to return SPDK_BDEV_IO_STATUS_NEEDS_RETRY in this case?\n\nI\u0027m not expert of error handling but my concern is the following. Reset is for error handling and error handling is generally hierarchical in each layer of storage stack. If one command fails or timeouts, stronger command is tried. The caller will not stop error handling until getting conclusion. I think we have to do serialize reset at any layer in the stack, i.e. just queueing and processing one-by-one. I don\u0027t think queueing + batched completion is viable approach.",
      "parentUuid": "3503414d_8bf0c43c",
      "range": {
        "startLine": 377,
        "startChar": 53,
        "endLine": 377,
        "endChar": 79
      },
      "revId": "6b215297ba9451f96ffeceb9e8dca03ae4887444",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "c68a2560_5e14cb0b",
        "filename": "module/bdev/nvme/bdev_nvme.c",
        "patchSetId": 4
      },
      "lineNbr": 377,
      "author": {
        "id": 1011223
      },
      "writtenOn": "2019-11-13T21:52:37Z",
      "side": 1,
      "message": "I have decided to go with your original suggestion. I am using the original idea of queueing resets at the bdev_nvme layer.",
      "parentUuid": "a60c8a3e_b9c0bd22",
      "range": {
        "startLine": 377,
        "startChar": 53,
        "endLine": 377,
        "endChar": 79
      },
      "revId": "6b215297ba9451f96ffeceb9e8dca03ae4887444",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "434777d3_f6b39452",
        "filename": "module/bdev/nvme/bdev_nvme.c",
        "patchSetId": 4
      },
      "lineNbr": 377,
      "author": {
        "id": 1016482
      },
      "writtenOn": "2019-11-14T10:40:50Z",
      "side": 1,
      "message": "I don\u0027t understand a bit why do we need to queue resets? If the user/bdev_nvme layer itself decided to reset the controller simultaneously and we queue the 2nd reset request then we will have 2 resets in a row. I think 1 reset is enough to e.g. restore transport layer failures, the second reset will do nothing useful. Probably we can just complete bio (if any) with success SPDK_BDEV_IO_STATUS_SUCCESS code\nAt least NVME controller itself doesn\u0027t queue reset request if the reset is already in progress.",
      "parentUuid": "c68a2560_5e14cb0b",
      "range": {
        "startLine": 377,
        "startChar": 53,
        "endLine": 377,
        "endChar": 79
      },
      "revId": "6b215297ba9451f96ffeceb9e8dca03ae4887444",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "1cbbb833_69d6ecd7",
        "filename": "module/bdev/nvme/bdev_nvme.c",
        "patchSetId": 4
      },
      "lineNbr": 377,
      "author": {
        "id": 1012251
      },
      "writtenOn": "2019-11-14T13:31:27Z",
      "side": 1,
      "message": "Hi Seth, Alexey,\n\nI was confused and wrong. SPDK SCSI controller queues and serializes resets. Even if multiple SCSI controller share a single NVMe controller, they are coordinated and resets are serialized. So uncoordinated resets are unlikely. Hence complex queueing is not necessary. I think returning success in the middle of reset may not be intuitive. Hence returning busy or error may be used as Seth originally proposed. Anyway I apologize for confusing you and thank you for your insight.\n-Shuhei",
      "parentUuid": "434777d3_f6b39452",
      "range": {
        "startLine": 377,
        "startChar": 53,
        "endLine": 377,
        "endChar": 79
      },
      "revId": "6b215297ba9451f96ffeceb9e8dca03ae4887444",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "8d504907_49a2d016",
        "filename": "module/bdev/nvme/bdev_nvme.c",
        "patchSetId": 4
      },
      "lineNbr": 377,
      "author": {
        "id": 1011223
      },
      "writtenOn": "2019-11-14T17:08:14Z",
      "side": 1,
      "message": "So there are a few different ways to handle this, and from discussions with all of you, I have found support for all of them. My favorite solution is bullet 4, but I\u0027d like to get buy in from everyone.\n\n1. My initial patch - If a reset is already in progress just fail the new incoming reset.\nPro: we don\u0027t have to have the extra callback code.\nCon: If the upper layer has a bigger hammer, it may try to use that to destroy the controller or something when really we are in the middle of what amounts to a successful reset.\n2. Alexey\u0027s Idea - If a reset is already in progress complete the bdevio with a successful.\nPro: same as above\nCon: you think you successfully reset a controller and start submitting I/O, but you get failures back.\n3. Current patch - If a reset is in progress queue the new one and then complete it in serial after the old one completes.\nPros: This is actually how the generic bdev module code handles resets. It respects the user request in a literal sense and ensures that the return value of the bdevio represents the actual return value of the reset that was queued.\nCons: Possibly doing more resets than necessary. If a reset succeeds, it has done the work that all of the queued resets want done. So doing a supplementary reset is a waste.\n4. Batched reset completions. Queue resets when one is in process. Complete all queued resets with the same return code that the original reset finishes with.\npros: The return code of the reset represents the actual current state of the controller without doing any additional work.\ncons: I don\u0027t actually see any cons with this strategy. I think we should do it this way but want to know what you all think.",
      "parentUuid": "1cbbb833_69d6ecd7",
      "range": {
        "startLine": 377,
        "startChar": 53,
        "endLine": 377,
        "endChar": 79
      },
      "revId": "6b215297ba9451f96ffeceb9e8dca03ae4887444",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735",
      "unresolved": true
    }
  ]
}